# Comparative Analysis of MFCC, Mel-Spectrogram, and STFT Features for Spoken Digit Classification
The accuracy of automatic speech recognition (ASR) systems is highly dependent on the effectiveness of the feature extraction stage in representing the audio signal. This study presents a comparative analysis of three fundamental digital signal processing techniques for feature extraction in the task of spoken digit classification: Mel-Frequency Cepstral Coefficients (MFCCs), Mel-spectrograms, and the Short-Time Fourier Transform (STFT). The core of this research involves applying these methods to raw audio signals to transform them into informative feature representations. The MFCCs capture the spectral envelope, Mel-spectrograms provide a perceptually relevant time-frequency representation, and the STFT offers a direct linear time-frequency analysis. These extracted features are then used to train a standard machine learning classifier to evaluate their discriminative power. Experimental results on a spoken digit dataset indicate that MFCC features consistently yield the highest classification accuracy, as they are specifically designed to model human auditory perception. The Mel-spectrogram also demonstrates strong performance, while the standard STFT magnitude, though computationally straightforward, proves to be less effective for this task. This work underscores the critical role of tailored digital signal processing in optimizing feature extraction for audio classification.
